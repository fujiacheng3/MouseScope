#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–å·¥å…·æ¨¡å—
æä¾›å†…å­˜ç®¡ç†ã€GPUæ£€æµ‹ç­‰å·¥å…·å‡½æ•°
"""

import gc
import os
import cv2
import numpy as np
from typing import Optional, Tuple

def force_memory_cleanup():
    """
    å¼ºåˆ¶å†…å­˜æ¸…ç†
    åœ¨å¤„ç†å¤§æ–‡ä»¶æˆ–é•¿æ—¶é—´è¿è¡Œåè°ƒç”¨
    """
    gc.collect()
    try:
        # å¦‚æœä½¿ç”¨CUDAï¼Œæ¸…ç†GPUå†…å­˜
        if cv2.cuda.getCudaEnabledDeviceCount() > 0:
            # OpenCV CUDAå†…å­˜ç®¡ç†
            pass  # OpenCVçš„CUDAä¼šè‡ªåŠ¨ç®¡ç†
    except:
        pass


def get_optimal_chunk_size(file_size_bytes: int) -> int:
    """
    æ ¹æ®æ–‡ä»¶å¤§å°è¿”å›æœ€ä¼˜çš„chunkå¤§å°
    
    å‚æ•°:
        file_size_bytes: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    
    è¿”å›:
        æœ€ä¼˜chunkå¤§å°ï¼ˆå­—èŠ‚ï¼‰
    """
    if file_size_bytes < 100 * 1024 * 1024:  # < 100MB
        return 8 * 1024 * 1024  # 8MB
    elif file_size_bytes < 500 * 1024 * 1024:  # < 500MB
        return 16 * 1024 * 1024  # 16MB
    else:  # >= 500MB
        return 32 * 1024 * 1024  # 32MB


def get_gpu_info() -> dict:
    """
    è·å–GPUä¿¡æ¯
    
    è¿”å›:
        åŒ…å«GPUçŠ¶æ€çš„å­—å…¸
    """
    info = {
        'cuda_available': False,
        'cuda_devices': 0,
        'current_device': None,
        'device_name': None,
    }
    
    try:
        info['cuda_devices'] = cv2.cuda.getCudaEnabledDeviceCount()
        if info['cuda_devices'] > 0:
            info['cuda_available'] = True
            info['current_device'] = cv2.cuda.getDevice()
            # å°è¯•è·å–è®¾å¤‡åç§°
            try:
                import torch
                if torch.cuda.is_available():
                    info['device_name'] = torch.cuda.get_device_name(0)
            except:
                pass
    except:
        pass
    
    return info


def optimize_video_writer_params(fps: float, quality: str = 'balanced') -> Tuple[str, dict]:
    """
    è¿”å›ä¼˜åŒ–çš„è§†é¢‘ç¼–ç å™¨å‚æ•°
    
    å‚æ•°:
        fps: å¸§ç‡
        quality: 'fast' (æœ€å¿«), 'balanced' (å¹³è¡¡), 'quality' (é«˜è´¨é‡)
    
    è¿”å›:
        (codec, params) å…ƒç»„
    """
    # å°è¯•ä½¿ç”¨çš„ç¼–ç å™¨ï¼ˆæŒ‰é€Ÿåº¦æ’åºï¼‰
    if quality == 'fast':
        # æœ€å¿«æ¨¡å¼ï¼šç‰ºç‰²ä¸€äº›è´¨é‡æ¢å–é€Ÿåº¦
        codecs = [
            ('avc1', {}),  # H.264ï¼ˆæœ€å¿«ï¼‰
            ('X264', {}),
            ('mp4v', {}),
        ]
    elif quality == 'quality':
        # é«˜è´¨é‡æ¨¡å¼ï¼šç¨æ…¢ä½†è´¨é‡æ›´å¥½
        codecs = [
            ('avc1', {}),
            ('H264', {}),
            ('mp4v', {}),
        ]
    else:  # balanced
        # å¹³è¡¡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        codecs = [
            ('avc1', {}),
            ('H264', {}),
            ('X264', {}),
            ('mp4v', {}),
        ]
    
    return codecs


def check_opencv_optimizations() -> dict:
    """
    æ£€æŸ¥OpenCVæ˜¯å¦å¯ç”¨äº†ä¼˜åŒ–
    
    è¿”å›:
        ä¼˜åŒ–çŠ¶æ€å­—å…¸
    """
    info = {
        'num_threads': cv2.getNumThreads(),
        'use_optimized': cv2.useOptimized(),
        'build_info': {},
    }
    
    # è§£ææ„å»ºä¿¡æ¯
    build = cv2.getBuildInformation()
    for line in build.split('\n'):
        if 'CUDA' in line or 'OPENCL' in line or 'TBB' in line or 'IPP' in line:
            info['build_info'][line.strip()] = True
    
    return info


def auto_set_opencv_threads(num_videos: int = 1):
    """
    è‡ªåŠ¨è®¾ç½®OpenCVçº¿ç¨‹æ•°
    
    å‚æ•°:
        num_videos: åŒæ—¶å¤„ç†çš„è§†é¢‘æ•°é‡
    """
    import os
    cpu_count = os.cpu_count() or 4
    
    # å¦‚æœåªå¤„ç†ä¸€ä¸ªè§†é¢‘ï¼Œä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    if num_videos == 1:
        optimal_threads = max(1, cpu_count - 1)  # ç•™ä¸€ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
    else:
        # å¤šè§†é¢‘å¹¶è¡Œæ—¶ï¼Œæ¯ä¸ªè§†é¢‘åˆ†é…è¾ƒå°‘çº¿ç¨‹
        optimal_threads = max(1, (cpu_count - 1) // num_videos)
    
    cv2.setNumThreads(optimal_threads)
    return optimal_threads


def enable_opencv_optimizations():
    """
    å¯ç”¨OpenCVä¼˜åŒ–
    åœ¨ç¨‹åºå¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡
    """
    # å¯ç”¨ä¼˜åŒ–ä»£ç 
    cv2.setUseOptimized(True)
    
    # å¦‚æœæœ‰å¤šçº¿ç¨‹æ”¯æŒï¼Œè‡ªåŠ¨è®¾ç½®çº¿ç¨‹æ•°
    auto_set_opencv_threads()
    
    print(f"âœ“ OpenCVä¼˜åŒ–å·²å¯ç”¨")
    print(f"  - çº¿ç¨‹æ•°: {cv2.getNumThreads()}")
    print(f"  - ä¼˜åŒ–ä»£ç : {cv2.useOptimized()}")


if __name__ == '__main__':
    """æµ‹è¯•æ€§èƒ½å·¥å…·"""
    print("=" * 50)
    print("æ€§èƒ½ä¼˜åŒ–å·¥å…·æµ‹è¯•")
    print("=" * 50)
    
    # GPUä¿¡æ¯
    gpu_info = get_gpu_info()
    print("\nğŸ® GPUä¿¡æ¯:")
    print(f"  CUDAå¯ç”¨: {gpu_info['cuda_available']}")
    print(f"  CUDAè®¾å¤‡æ•°: {gpu_info['cuda_devices']}")
    if gpu_info['device_name']:
        print(f"  è®¾å¤‡åç§°: {gpu_info['device_name']}")
    
    # OpenCVä¼˜åŒ–
    print("\nâš™ï¸  OpenCVä¼˜åŒ–çŠ¶æ€:")
    enable_opencv_optimizations()
    
    opt_info = check_opencv_optimizations()
    print(f"  æ„å»ºä¿¡æ¯: {len(opt_info['build_info'])} é¡¹ä¼˜åŒ–ç‰¹æ€§")
    
    print("\nâœ“ æµ‹è¯•å®Œæˆ")

